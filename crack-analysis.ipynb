{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1378596,"sourceType":"datasetVersion","datasetId":804181},{"sourceId":1648251,"sourceType":"datasetVersion","datasetId":974687},{"sourceId":2928272,"sourceType":"datasetVersion","datasetId":1795034},{"sourceId":35515707,"sourceType":"kernelVersion"},{"sourceId":53915625,"sourceType":"kernelVersion"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ========================================\n# 1) Install dependencies\n# ========================================\n!pip install -q efficientnet tensorflow scikit-learn\n\n# ========================================\n# 2) Imports\n# ========================================\nimport tensorflow as tf\nimport efficientnet.tfkeras as efn\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import f1_score, classification_report\nimport numpy as np\n\n# ========================================\n# 3) Data Generators\n# ========================================\nIMG_SIZE = 224\nBATCH_SIZE = 32\nDATA_DIR = \"/kaggle/input/structural-defects-network-concrete-crack-images/Decks\"\n\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2\n)\n\ntrain_gen = datagen.flow_from_directory(\n    DATA_DIR,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='training',\n    shuffle=True\n)\n\nval_gen = datagen.flow_from_directory(\n    DATA_DIR,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='binary',\n    subset='validation',\n    shuffle=False\n)\n\n# ========================================\n# 4) Build EfficientNetB0 Model\n# ========================================\nbase_model = efn.EfficientNetB0(\n    weights='imagenet',\n    include_top=False,\n    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n)\nbase_model.trainable = False  # freeze feature extractor\n\nx = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\nx = tf.keras.layers.Dense(64, activation='relu')(x)\noutput = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n\nmodel = tf.keras.Model(inputs=base_model.input, outputs=output)\n\nmodel.compile(optimizer='adam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\n# ========================================\n# 5) Train Model\n# ========================================\nhistory = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=5\n)\n\n# ========================================\n# 6) Evaluate F1 Score\n# ========================================\n# Get predictions\nval_gen.reset()\npreds = (model.predict(val_gen) > 0.5).astype(int)\ntrue_labels = val_gen.classes\n\n# Classification report\nprint(classification_report(true_labels, preds, digits=4))\nprint(\"F1 Score:\", f1_score(true_labels, preds))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-09T21:08:59.729068Z","iopub.execute_input":"2025-08-09T21:08:59.729399Z","iopub.status.idle":"2025-08-09T21:12:56.136119Z","shell.execute_reply.started":"2025-08-09T21:08:59.729346Z","shell.execute_reply":"2025-08-09T21:12:56.135133Z"}},"outputs":[{"name":"stdout","text":"Found 10896 images belonging to 2 classes.\nFound 2724 images belonging to 2 classes.\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1754773755.666273      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b0_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n\u001b[1m16804768/16804768\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1754773773.687620     134 service.cc:148] XLA service 0x794f8814d1a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1754773773.688391     134 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1754773775.392833     134 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  1/341\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:22:01\u001b[0m 25s/step - accuracy: 0.9062 - loss: 0.5638","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1754773784.206635     134 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 204ms/step - accuracy: 0.8786 - loss: 0.3376 - val_accuracy: 0.9174 - val_loss: 0.2498\nEpoch 2/5\n\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 72ms/step - accuracy: 0.9070 - loss: 0.2721 - val_accuracy: 0.9159 - val_loss: 0.2525\nEpoch 3/5\n\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 78ms/step - accuracy: 0.9164 - loss: 0.2557 - val_accuracy: 0.9123 - val_loss: 0.2767\nEpoch 4/5\n\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 80ms/step - accuracy: 0.9132 - loss: 0.2521 - val_accuracy: 0.9236 - val_loss: 0.2379\nEpoch 5/5\n\u001b[1m341/341\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 75ms/step - accuracy: 0.9131 - loss: 0.2531 - val_accuracy: 0.9214 - val_loss: 0.2414\n\u001b[1m86/86\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 131ms/step\n              precision    recall  f1-score   support\n\n           0     0.8577    0.5654    0.6815       405\n           1     0.9284    0.9836    0.9552      2319\n\n    accuracy                         0.9214      2724\n   macro avg     0.8930    0.7745    0.8184      2724\nweighted avg     0.9179    0.9214    0.9145      2724\n\nF1 Score: 0.9551926298157454\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# ========================================\n# 1) Install dependencies\n# ========================================\n!pip install -q tensorflow scikit-learn segmentation-models\n\n# ========================================\n# 2) Imports\n# ========================================\nimport os\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nfrom sklearn.model_selection import train_test_split\nimport segmentation_models as sm\n\n# Set image size\nIMG_HEIGHT, IMG_WIDTH = 256, 256\nDATASET_PATH = \"/kaggle/input/concrete-crack-segmentation-dataset/concreteCrackSegmentationDataset\"  # change this to your dataset path\n\n# ========================================\n# 3) Load Data\n# ========================================\nimport os\nimport numpy as np\nfrom tensorflow.keras.utils import img_to_array, load_img\n\nIMG_HEIGHT, IMG_WIDTH = 256, 256\n\nimage_dir = \"/kaggle/input/concrete-crack-segmentation-dataset/concreteCrackSegmentationDataset/rgb\"\nmask_dir  = \"/kaggle/input/concrete-crack-segmentation-dataset/concreteCrackSegmentationDataset/BW\"\n\n# Keep only jpg files\nimage_files = [f for f in os.listdir(image_dir) if f.lower().endswith(\".jpg\")]\nmask_files  = [f for f in os.listdir(mask_dir) if f.lower().endswith(\".jpg\")]\n\n# Convert to name without extension for comparison\nimage_ids = set(os.path.splitext(f)[0] for f in image_files)\nmask_ids  = set(os.path.splitext(f)[0] for f in mask_files)\n\n# Intersection — only the IDs present in BOTH\ncommon_ids = sorted(image_ids & mask_ids)\nprint(f\"✅ Found {len(common_ids)} matching image-mask pairs.\")\n\nimages, masks = [], []\n\nfor file_id in common_ids:\n    img_path = os.path.join(image_dir, file_id + \".jpg\")\n    mask_path = os.path.join(mask_dir, file_id + \".jpg\")\n    \n    # Safety check\n    if not os.path.exists(img_path) or not os.path.exists(mask_path):\n        continue\n\n    img = load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n    img = img_to_array(img) / 255.0\n    images.append(img)\n\n    mask = load_img(mask_path, target_size=(IMG_HEIGHT, IMG_WIDTH), color_mode=\"grayscale\")\n    mask = img_to_array(mask) / 255.0\n    masks.append(mask)\n\nimages = np.array(images)\nmasks = np.array(masks)\n\nprint(\"Images shape:\", images.shape)\nprint(\"Masks shape:\", masks.shape)\n\n\n\n# ========================================\n# 4) Train-test split\n# ========================================\nX_train, X_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)\n\n# ========================================\n# 5) Build U-Net\n# ========================================\nsm.set_framework('tf.keras')\nsm.framework()\n\n# Use U-Net with a pretrained backbone\nBACKBONE = 'efficientnetb0'\npreprocess_input = sm.get_preprocessing(BACKBONE)\n\nX_train = preprocess_input(X_train)\nX_val = preprocess_input(X_val)\n\nmodel = sm.Unet(BACKBONE, encoder_weights='imagenet', classes=1, activation='sigmoid')\n\n# Dice loss + binary crossentropy\ndice_loss = sm.losses.DiceLoss()\nbce_loss  = sm.losses.BinaryCELoss() \ntotal_loss = dice_loss + bce_loss\n\nmetrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n\nmodel.compile(optimizer='adam', loss=total_loss, metrics=metrics)\n\n# ========================================\n# 6) Train\n# ========================================\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=5,\n    batch_size=8\n)\n\n# ========================================\n# 7) Evaluate\n# ========================================\nscores = model.evaluate(X_val, y_val, verbose=0)\nprint(f\"Mean IoU: {scores[1]:.4f}\")\nprint(f\"Dice Score: {scores[2]:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T21:37:16.512235Z","iopub.execute_input":"2025-08-09T21:37:16.513073Z","iopub.status.idle":"2025-08-09T21:41:28.572840Z","shell.execute_reply.started":"2025-08-09T21:37:16.513040Z","shell.execute_reply":"2025-08-09T21:41:28.571918Z"}},"outputs":[{"name":"stdout","text":"✅ Found 446 matching image-mask pairs.\nImages shape: (257, 256, 256, 3)\nMasks shape: (257, 256, 256, 1)\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1754775569.727740     137 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1754775569.912392     137 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1754775570.322753     137 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1754775570.527636     137 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m25/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - f1-score: 0.3606 - iou_score: 0.2323 - loss: 1.1952","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1754775615.431009     135 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1754775615.615639     135 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1754775616.018603     135 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\nE0000 00:00:1754775616.223432     135 gpu_timer.cc:82] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - f1-score: 0.3704 - iou_score: 0.2402 - loss: 1.1844 - val_f1-score: 0.0307 - val_iou_score: 0.0157 - val_loss: 3.9793\nEpoch 2/5\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - f1-score: 0.6713 - iou_score: 0.5064 - loss: 0.7025 - val_f1-score: 0.0405 - val_iou_score: 0.0208 - val_loss: 1.9932\nEpoch 3/5\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - f1-score: 0.7395 - iou_score: 0.5882 - loss: 0.4126 - val_f1-score: 0.0362 - val_iou_score: 0.0186 - val_loss: 3.2824\nEpoch 4/5\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - f1-score: 0.7843 - iou_score: 0.6459 - loss: 0.2942 - val_f1-score: 7.2057e-04 - val_iou_score: 3.6046e-04 - val_loss: 1.0666\nEpoch 5/5\n\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 95ms/step - f1-score: 0.7805 - iou_score: 0.6422 - loss: 0.2790 - val_f1-score: 0.0196 - val_iou_score: 0.0099 - val_loss: 1.1643\nMean IoU: 0.0097\nDice Score: 0.0192\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from google.colab import files\nfiles.upload()  # upload kaggle.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T20:54:12.283732Z","iopub.status.idle":"2025-08-09T20:54:12.283961Z","shell.execute_reply.started":"2025-08-09T20:54:12.283842Z","shell.execute_reply":"2025-08-09T20:54:12.283852Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\nos.system(\"mv kaggle.json ~/.kaggle/\")\nos.system(\"chmod 600 ~/.kaggle/kaggle.json\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-09T20:53:38.270531Z","iopub.execute_input":"2025-08-09T20:53:38.271138Z","iopub.status.idle":"2025-08-09T20:53:38.290091Z","shell.execute_reply.started":"2025-08-09T20:53:38.271099Z","shell.execute_reply":"2025-08-09T20:53:38.289308Z"}},"outputs":[{"name":"stderr","text":"mv: cannot stat 'kaggle.json': No such file or directory\nchmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"256"},"metadata":{}}],"execution_count":2}]}